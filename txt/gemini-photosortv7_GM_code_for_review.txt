{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 #!/usr/bin/env python3\
"""\
BakLLaVA Photo Organizer\
Renames photos using local vision model and organizes into smart groups.\
\
V7.0 (AI Critic) Update:\
- Adds '--critique' / '--art' command for V7.0.\
- Runs AI "Creative Director" prompt on a folder of images.\
- Saves detailed .json sidecar files for each image.\
- Integrates a global config file (~/.photosort.conf).\
\
V6.5 (Auto Mode) Update:\
- Renamed '--smart-ingest' to '--auto' for clarity\
- Reordered workflow: asks for config BEFORE processing\
- Extracted helper function to eliminate code duplication\
- Added validation checks after each automation step\
- Fixed duplicate print statement\
- Standardized emoji usage throughout\
\
V6.4 (Ready) Refactor:\
- Refactored main() to use a dispatch table instead of if/elif.\
- Added V6.4 (--stats) import block for 'exifread'.\
- Added calibration comments to CULL_THRESHOLDS.\
\
V6.3 (Smart Prep) Update:\
- Adds '--prep' / '--pe' flag to find "Good" tier images and\
  COPY them to a "_ReadyForLightroom" folder.\
\
V6.2 (Best Pick) Update:\
- Upgrades '--group-bursts' to analyze all images in a burst\
  and rename the sharpest one with "_PICK_".\
\
V6.0 (Cull Mode) Update:\
- Adds '--cull' / '-c' flag to analyze technical quality (sharpness, exposure).\
- Moves files into folders: _Keepers, _Review_Maybe, _Review_Duds\
- Requires 'pip install opencv-python numpy'\
\
V5.0 (Burst Stacker) Update:\
- Adds '--group-bursts' / '-b' flag to find and group visually similar images.\
- Requires 'pip install imagehash'\
"""\
\
import os\
import json\
import base64\
import requests\
import shutil\
import tempfile\
import configparser\
from pathlib import Path\
from datetime import datetime\
from concurrent.futures import ThreadPoolExecutor, as_completed\
from typing import Optional, Tuple, List, Dict, Any\
from collections import defaultdict, Counter\
import re\
import subprocess\
import sys\
import math\
from io import BytesIO\
\
# --- V5.0: Burst Stacker Imports ---\
V5_LIBS_MSG = " FATAL: '--group-bursts' requires the 'imagehash' library.\\n   Please run: pip install imagehash"\
try:\
    import imagehash\
    from PIL import Image, ImageFile\
    ImageFile.LOAD_TRUNCATED_IMAGES = True\
    V5_LIBS_AVAILABLE = True\
except ImportError:\
    V5_LIBS_AVAILABLE = False\
\
# --- V6.0: Cull Mode Imports ---\
V6_LIBS_MSG = " FATAL: '--cull' or '--prep' requires 'opencv-python' and 'numpy'.\\n   Please run: pip install opencv-python numpy"\
try:\
    import cv2\
    import numpy as np\
    V6_CULL_LIBS_AVAILABLE = True\
except ImportError:\
    V6_CULL_LIBS_AVAILABLE = False\
\
# --- V6.4: EXIF Stats Imports ---\
V6_4_LIBS_MSG = " FATAL: '--stats' requires the 'exifread' library.\\n   Please run: pip install exifread"\
try:\
    import exifread\
    V6_4_EXIF_LIBS_AVAILABLE = True\
except ImportError:\
    V6_4_EXIF_LIBS_AVAILABLE = False\
\
# Try to import tqdm for progress bar\
try:\
    from tqdm import tqdm\
    TQDM_AVAILABLE = True\
except ImportError:\
    TQDM_AVAILABLE = False\
    print(" Tip: Install tqdm for progress bars: pip3 install tqdm")\
\
# Check if dcraw is available for RAW support\
def check_dcraw():\
    """Check if dcraw is available"""\
    try:\
        result = subprocess.run(['which', 'dcraw'], capture_output=True, text=True)\
        return result.returncode == 0 and result.stdout.strip()\
    except Exception:\
        return False\
\
RAW_SUPPORT = check_dcraw()\
\
# --- Configuration ---\
# V7.0: These are now the *default fallbacks* if config file is missing.\
OLLAMA_URL = "http://localhost:11434/api/chat"\
DEFAULT_MODEL_NAME = "bakllava"\
DEFAULT_DESTINATION_BASE = Path.home() / "Library/Mobile Documents/com~apple~CloudDocs/negatives"\
DEFAULT_CRITIQUE_MODEL = "openbmb/minicpm-v2.6:q4_K_M"\
\
# Calibrated thresholds based on real Lumix .RW2 testing:\
DEFAULT_CULL_THRESHOLDS = \{\
    'sharpness_good': 40.0,\
    'sharpness_dud': 15.0,\
    'exposure_dud_pct': 0.20,\
    'exposure_good_pct': 0.05\
\}\
DEFAULT_BURST_THRESHOLD = 8\
\
# V7.0: Config file path\
CONFIG_FILE_PATH = Path.home() / ".photosort.conf"\
\
SUPPORTED_EXTENSIONS = \{'.jpg', '.jpeg', '.png'\}\
if RAW_SUPPORT:\
    SUPPORTED_EXTENSIONS.add('.rw2')\
MAX_WORKERS = 5\
INGEST_TIMEOUT = 60  # seconds per image\
CRITIQUE_TIMEOUT = 120 # seconds per image (V7.0)\
\
# Session date for organizing this batch\
SESSION_DATE = datetime.now().strftime("%Y-%m-%d")\
SESSION_TIMESTAMP = datetime.now().strftime("%Y-%m-%d_%H%M")\
\
# Keywords for grouping (you can customize these!)\
GROUP_KEYWORDS = \{\
    "Architecture": ["building", "architecture", "structure", "facade", "construction", "tower", "bridge", "monument"],\
    "Street-Scenes": ["street", "road", "sidewalk", "crosswalk", "traffic", "urban", "city"],\
    "People": ["people", "person", "man", "woman", "child", "crowd", "pedestrian", "walking"],\
    "Nature": ["tree", "forest", "mountain", "lake", "river", "ocean", "beach", "sunset", "sunrise", "sky", "cloud"],\
    "Transportation": ["car", "bus", "train", "trolley", "vehicle", "bicycle", "scooter", "motorcycle"],\
    "Signs-Text": ["sign", "text", "billboard", "poster", "graffiti", "writing"],\
    "Food-Dining": ["food", "restaurant", "cafe", "produce", "market", "vendor", "stand"],\
    "Animals": ["dog", "cat", "bird", "animal", "pet"],\
    "Interior": ["interior", "room", "inside", "indoor"],\
\}\
\
# --- V5.0: Burst Stacker Configuration ---\
BURST_SIMILARITY_THRESHOLD = 8 # V7.0: This is now a fallback, overridden by config\
\
# --- V6.0: Cull Mode Configuration ---\
CULL_THRESHOLDS = DEFAULT_CULL_THRESHOLDS # V7.0: This is now a fallback, overridden by config\
\
# --- V6.2: "Best Pick" Prefix ---\
BEST_PICK_PREFIX = "_PICK_"\
\
# --- V6.3: Smart Prep ---\
PREP_FOLDER_NAME = "_ReadyForLightroom"\
\
# --- V7.0: AI Critic "Gold Master" Prompt ---\
AI_CRITIC_PROMPT = """\
You are a professional Creative Director and magazine photo editor. Your job is to provide ambitious, artistic, and creative feedback to elevate a photo from "good" to "great."\
\
**CREATIVE TOOLBOX (Use these for your suggestion):**\
* **Mood & Atmosphere:** (e.g., 'cinematic,' 'moody,' 'ethereal,' 'nostalgic,' 'dramatic')\
* **Color Grading:** (e.g., 'filmic teal-orange,' 'warm vintage,' 'cool desaturation,' 'split-toning')\
* **Light & Shadow:** (e.g., 'crushed blacks,' 'soft, lifted shadows,' 'localized dodging/burning,' 'a subtle vignette')\
* **Texture:** (e.g., 'add fine film grain,' 'soften the focus,' 'increase clarity')\
\
**YOUR TASK:**\
Analyze the provided image by following these steps *internally*:\
1.  **Composition:** Analyze balance, guiding principles (thirds, lines), and subject placement. Rate it 1-10.\
2.  **Lighting & Exposure:** Analyze quality, direction, temperature, and any blown highlights or crushed shadows.\
3.  **Color & Style:** Analyze the color palette, white balance, and current post-processing style.\
\
After your analysis, you MUST return **ONLY a single, valid JSON object**. Do not provide *any* other text, preamble, or conversation. Your response must be 100% valid JSON, formatted *exactly* like this template:\
\
```json\
\{\
  "composition_score": <an integer from 1 to 10>,\
  "composition_critique": "<A brief, one-sentence critique of the composition.>",\
  "lighting_critique": "<A brief, one-sentence critique of the lighting and exposure.>",\
  "color_critique": "<A brief, one-sentence critique of the color and current style.>",\
  "final_verdict": "<A one-sentence summary of what works and what doesn't.>",\
  "creative_mood": "<The single, most ambitious 'Creative Mood' this photo could have, chosen from the toolbox.>",\
  "creative_suggestion": "<Your single, ambitious, artistic post-processing suggestion to achieve that mood. This must be a detailed, actionable paragraph. **Example:** To achieve a 'Cinematic & Moody' feel, apply a teal-orange color grade, slightly crush the blacks to add contrast, and use localized burning on the edges to pull the eye to the subject.>"\
\}\
```\
"""\
\
\
def load_app_config() -> Dict[str, Any]:\
    """\
    V7.0: Loads settings from ~/.photosort.conf\
    Uses hardcoded defaults as fallbacks.\
    """\
    parser = configparser.ConfigParser()\
    if CONFIG_FILE_PATH.exists():\
        parser.read(CONFIG_FILE_PATH)\
        print(f" \uc0\u9432  Loaded config from: \{CONFIG_FILE_PATH\}")\
\
    config = \{\}\
\
    # Ingest settings\
    config['default_destination'] = Path(parser.get(\
        'ingest', 'default_destination',\
        fallback=str(DEFAULT_DESTINATION_BASE)\
    )).expanduser()\
    config['default_model'] = parser.get(\
        'ingest', 'default_model',\
        fallback=DEFAULT_MODEL_NAME\
    )\
\
    # Cull thresholds\
    config['cull_thresholds'] = \{\
        'sharpness_good': parser.getfloat('cull', 'sharpness_good', fallback=DEFAULT_CULL_THRESHOLDS['sharpness_good']),\
        'sharpness_dud': parser.getfloat('cull', 'sharpness_dud', fallback=DEFAULT_CULL_THRESHOLDS['sharpness_dud']),\
        'exposure_dud_pct': parser.getfloat('cull', 'exposure_dud_pct', fallback=DEFAULT_CULL_THRESHOLDS['exposure_dud_pct']),\
        'exposure_good_pct': parser.getfloat('cull', 'exposure_good_pct', fallback=DEFAULT_CULL_THRESHOLDS['exposure_good_pct']),\
    \}\
\
    # Burst threshold\
    config['burst_threshold'] = parser.getint(\
        'burst', 'similarity_threshold',\
        fallback=DEFAULT_BURST_THRESHOLD\
    )\
\
    # V7.0 Critique settings\
    config['critique_model'] = parser.get(\
        'critique', 'default_model',\
        fallback=DEFAULT_CRITIQUE_MODEL\
    )\
\
    return config\
\
\
def get_available_models() -> Optional[List[str]]:\
    """\
    Get list of available Ollama models.\
    Returns None if Ollama is unavailable (fail-fast check).\
    """\
    try:\
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, check=True)\
        lines = result.stdout.strip().split('\\n')[1:]  # Skip header\
        models = [line.split()[0] for line in lines if line.strip()]\
        return models\
    except subprocess.CalledProcessError:\
        return None\
    except FileNotFoundError:\
        return None\
    except Exception:\
        return None\
\
\
def convert_raw_to_jpeg(raw_path: Path) -> Optional[bytes]:\
    """Convert RAW file to JPEG bytes using dcraw"""\
    if not RAW_SUPPORT:\
        return None\
    \
    try:\
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:\
            tmp_jpg = tmp.name\
        \
        # Use dcraw to convert RAW to PPM (in memory)\
        result = subprocess.run(\
            ['dcraw', '-c', '-w', '-q', '3', str(raw_path)],\
            capture_output=True,\
            check=True\
        )\
        \
        # Write PPM to a temp file\
        with tempfile.NamedTemporaryFile(suffix='.ppm', delete=False) as ppm_tmp:\
            ppm_tmp.write(result.stdout)\
            ppm_file = ppm_tmp.name\
        \
        # Use sips to convert PPM to JPEG (macOS specific)\
        subprocess.run(\
            ['sips', '-s', 'format', 'jpeg', ppm_file, '--out', tmp_jpg],\
            capture_output=True,\
            check=True\
        )\
        \
        with open(tmp_jpg, 'rb') as f:\
            jpeg_bytes = f.read()\
        \
        # Clean up temp files\
        os.unlink(ppm_file)\
        os.unlink(tmp_jpg)\
        \
        return jpeg_bytes\
    \
    except Exception as e:\
        print(f" Error converting RAW file: \{e\}")\
        try:\
            if 'ppm_file' in locals():\
                os.unlink(ppm_file)\
            if 'tmp_jpg' in locals() and os.path.exists(tmp_jpg):\
                os.unlink(tmp_jpg)\
        except:\
            pass\
        return None\
\
\
def encode_image(image_path: Path) -> Optional[str]:\
    """Convert image to base64 string, handling RAW files"""\
    try:\
        if image_path.suffix.lower() == '.rw2':\
            jpeg_bytes = convert_raw_to_jpeg(image_path)\
            if jpeg_bytes:\
                return base64.b64encode(jpeg_bytes).decode('utf-8')\
            else:\
                return None\
        \
        with open(image_path, 'rb') as img_file:\
            return base64.b64encode(img_file.read()).decode('utf-8')\
    \
    except Exception as e:\
        print(f" Error encoding \{image_path.name\}: \{e\}")\
        return None\
\
\
def get_image_hash(image_path: Path) -> Optional[tuple[Path, imagehash.ImageHash]]:\
    """\
    Calculates perceptual hash (visual fingerprint) of an image.\
    V6.5: Simplified RAW thumbnail extraction.\
    """\
    if image_path.suffix.lower() in ['.rw2', '.cr2', '.nef', '.arw', '.dng']:\
        try:\
            # Extract embedded JPEG thumbnail directly\
            result = subprocess.run(\
                ['dcraw', '-e', '-c', str(image_path)],\
                capture_output=True,\
                check=True\
            )\
            # PIL can read JPEG from memory\
            img = Image.open(BytesIO(result.stdout))\
            return image_path, imagehash.phash(img)\
        except Exception:\
            return image_path, None\
           \
    # For regular JPG/PNG files\
    try:\
        with Image.open(image_path) as img:\
            return image_path, imagehash.phash(img)\
    except Exception as e:\
        print(f"     Skipping hash for \{image_path.name\}: \{e\}")\
        return image_path, None\
\
\
def get_ai_description(image_path: Path, model_name: str) -> Optional[str]:\
    """(V4.0) Get filename suggestion from vision model"""\
    base64_image = encode_image(image_path)\
    if not base64_image:\
        return None\
    \
    payload = \{\
        "model": model_name,\
        "messages": [\
            \{\
                "role": "user",\
                "content": "What is in this image? Describe it concisely for a file name.",\
                "images": [base64_image]\
            \}\
        ],\
        "stream": False\
    \}\
    \
    try:\
        response = requests.post(OLLAMA_URL, json=payload, timeout=INGEST_TIMEOUT)\
        response.raise_for_status()\
        \
        result = response.json()\
        description = result['message']['content'].strip()\
        \
        return description\
        \
    except requests.exceptions.Timeout:\
        print(f"  Timeout processing \{image_path.name\}")\
        return None\
    except Exception as e:\
        print(f" Error processing \{image_path.name\}: \{e\}")\
        return None\
\
\
def get_ai_critique(image_path: Path, model_name: str) -> Optional[str]:\
    """(V7.0) Get AI "Creative Director" critique as a JSON string"""\
    base64_image = encode_image(image_path)\
    if not base64_image:\
        return None\
    \
    payload = \{\
        "model": model_name,\
        "messages": [\
            \{\
                "role": "user",\
                "content": AI_CRITIC_PROMPT,\
                "images": [base64_image]\
            \}\
        ],\
        "stream": False,\
        "format": "json" # Force JSON output if model supports it\
    \}\
    \
    try:\
        response = requests.post(OLLAMA_URL, json=payload, timeout=CRITIQUE_TIMEOUT)\
        response.raise_for_status()\
        \
        result = response.json()\
        json_string = result['message']['content'].strip()\
        \
        return json_string\
        \
    except requests.exceptions.Timeout:\
        print(f"  Timeout getting critique for \{image_path.name\}")\
        return None\
    except Exception as e:\
        print(f" Error getting critique for \{image_path.name\}: \{e\}")\
        return None\
\
\
def clean_filename(description: str) -> str:\
    """Convert AI description to clean filename"""\
    clean = description.strip('"\\'.,!?')\
    clean = re.sub(r'[^\\w\\s-]', '', clean)\
    clean = re.sub(r'[-\\s]+', '-', clean)\
    clean = clean.lower()[:60]\
    return clean.strip('-')\
\
\
def get_unique_filename(base_name: str, extension: str, destination: Path) -> Path:\
    """Generate unique filename if file already exists"""\
    filename = destination / f"\{base_name\}\{extension\}"\
    \
    if not filename.exists():\
        return filename\
    \
    counter = 1\
    while True:\
        filename = destination / f"\{base_name\}-\{counter:02d\}\{extension\}"\
        if not filename.exists():\
            return filename\
        counter += 1\
\
\
def categorize_description(description: str) -> str:\
    """Determine category based on keywords in description"""\
    description_lower = description.lower()\
    \
    category_scores = \{\}\
    for category, keywords in GROUP_KEYWORDS.items():\
        score = sum(1 for keyword in keywords if keyword in description_lower)\
        if score > 0:\
            category_scores[category] = score\
    \
    if category_scores:\
        return max(category_scores, key=category_scores.get)\
    return "Miscellaneous"\
\
\
def process_single_image(image_path: Path, destination_base: Path, model_name: str, dry_run: bool) -> Tuple[Path, bool, str, str]:\
    """Process one image: get description, rename, move to temp location"""\
    try:\
        description = get_ai_description(image_path, model_name)\
        if not description:\
            return image_path, False, "Failed to get AI description", ""\
        \
        clean_name = clean_filename(description)\
        if not clean_name:\
            clean_name = f"image-\{datetime.now().strftime('%Y%m%d-%H%M%S')\}"\
        \
        extension = image_path.suffix.lower()\
        new_path = get_unique_filename(clean_name, extension, destination_base)\
        \
        if not dry_run:\
            shutil.move(str(image_path), str(new_path))\
        \
        return image_path, True, new_path.name, description\
        \
    except Exception as e:\
        return image_path, False, str(e), ""\
\
\
def organize_into_folders(processed_files: List[Dict], destination_base: Path, dry_run: bool):\
    """Group files into folders based on their descriptions"""\
    print(f"\\n\{'='*60\}")\
    print(" \uc0\u55357 \u56770 \u65039   Organizing into smart folders...")\
    print(f"\{'='*60\}\\n")\
    \
    categories = defaultdict(list)\
    for file_info in processed_files:\
        filename = file_info['new_name']\
        description = file_info['description']\
        category = categorize_description(description)\
        categories[category].append(\{\
            'filename': filename,\
            'description': description\
        \})\
    \
    for category, files in categories.items():\
        folder_name = f"\{SESSION_DATE\}_\{category\}"\
        folder_path = destination_base / folder_name\
        \
        if not dry_run:\
            folder_path.mkdir(exist_ok=True)\
        \
        print(f" \{folder_name\}/ (\{len(files)\} files)")\
        \
        for file_info in files:\
            src = destination_base / file_info['filename']\
            dst = folder_path / file_info['filename']\
            \
            if not dry_run:\
                if src.exists():\
                    shutil.move(str(src), str(dst))\
            else:\
                print(f"   [PREVIEW] Would move \{file_info['filename']\} here")\
    \
    print(f"\\n Organized into \{len(categories)\} folders")\
\
\
def process_directory(directory: Path, destination_base: Path, model_name: str, dry_run: bool, max_workers: int = MAX_WORKERS):\
    """(DEFAULT MODE) Process all images with AI, rename, and organize"""\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("  No supported image files found in current directory")\
        print(f"   Looking for: \{', '.join(SUPPORTED_EXTENSIONS)\}")\
        return\
    \
    print(f"\\n Found \{len(image_files)\} images to process")\
    print(f" Destination: \{destination_base\}")\
    print(f" Model: \{model_name\}")\
    print(f"  Using \{max_workers\} concurrent workers")\
    if RAW_SUPPORT:\
        print(" \uc0\u55357 \u56568  RAW support enabled (dcraw)")\
    print(f"\{'='*60\}\\n")\
    \
    results = \{"success": [], "failed": []\}\
    \
    if TQDM_AVAILABLE:\
        pbar = tqdm(total=len(image_files), desc=" \uc0\u55358 \u56598  Processing images", unit="img", ncols=80)\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_file = \{\
            executor.submit(process_single_image, img, destination_base, model_name, dry_run): img \
            for img in image_files\
        \}\
        \
        for future in as_completed(future_to_file):\
            original, success, message, description = future.result()\
            \
            if success:\
                results["success"].append(\{\
                    "original": original.name,\
                    "new_name": message,\
                    "description": description\
                \})\
            else:\
                results["failed"].append((original.name, message))\
                if TQDM_AVAILABLE:\
                    pbar.write(f" \uc0\u10060  \{original.name\}: \{message\}")\
                else:\
                    print(f" \uc0\u10060  \{original.name\}: \{message\}")\
            \
            if TQDM_AVAILABLE:\
                pbar.update(1)\
    \
    if TQDM_AVAILABLE:\
        pbar.close()\
    \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u9989  Successfully processed: \{len(results['success'])\}")\
    print(f" \uc0\u10060  Failed: \{len(results['failed'])\}")\
    \
    if results["failed"]:\
        print("\\n  Failed files:")\
        for orig, reason in results["failed"]:\
            print(f"   \'95 \{orig\}: \{reason\}")\
    \
    if results["success"]:\
        organize_into_folders(results["success"], destination_base, dry_run)\
    \
    log_file = destination_base / f"_import_log_\{SESSION_TIMESTAMP\}.json"\
    \
    if not dry_run:\
        with open(log_file, 'w') as f:\
            json.dump(\{\
                "session_date": SESSION_TIMESTAMP,\
                "source_directory": str(directory),\
                "destination_directory": str(destination_base),\
                "model_used": model_name,\
                "total_files": len(image_files),\
                "successful": results["success"],\
                "failed": [\{"original": o, "reason": r\} for o, r in results["failed"]],\
            \}, f, indent=2)\
        \
        print(f"\\n Log saved: \{log_file.name\}")\
    else:\
        print(f"\\n[PREVIEW] Would save log file to: \{log_file.name\}")\
\
\
def group_bursts_in_directory(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """\
    (V6.2) Finds and groups visually similar images into subfolders\
    and renames the sharpest file in the burst.\
    """\
    \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u55357 \u56568  BakLLaVA Photo Organizer --- (Burst Stacker Mode)")\
    print(f"\{'='*60\}")\
    print(f" Scanning for visually similar images in: \{directory\}")\
    \
    burst_threshold = APP_CONFIG['burst_threshold']\
    print(f"   (Similarity threshold: \{burst_threshold\})")\
    print(f"   (Sharpest image will be prefixed: \{BEST_PICK_PREFIX\})")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if len(image_files) < 2:\
        print("     Not enough images to compare. Exiting.")\
        return\
\
    all_hashes = \{\}\
    print("\\n Calculating visual fingerprints...")\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_path = \{executor.submit(get_image_hash, path): path for path in image_files\}\
        \
        iterable = as_completed(future_to_path)\
        if TQDM_AVAILABLE:\
            iterable = tqdm(iterable, total=len(image_files), desc="   Hashing", unit="img")\
\
        for future in iterable:\
            path, img_hash = future.result()\
            if img_hash:\
                all_hashes[path] = img_hash\
\
    print("\\n Comparing fingerprints to find burst groups...")\
    \
    visited_paths = set()\
    all_burst_groups = []\
    \
    sorted_paths = sorted(all_hashes.keys(), key=lambda p: p.name)\
    \
    for path in sorted_paths:\
        if path in visited_paths:\
            continue\
            \
        current_group = [path]\
        visited_paths.add(path)\
        \
        for other_path in sorted_paths:\
            if other_path in visited_paths:\
                continue\
                \
            hash1 = all_hashes.get(path)\
            hash2 = all_hashes.get(other_path)\
            \
            if hash1 and hash2:\
                distance = hash1 - hash2\
                if distance <= burst_threshold:\
                    current_group.append(other_path)\
                    visited_paths.add(other_path)\
        \
        if len(current_group) > 1:\
            all_burst_groups.append(current_group)\
\
    if not all_burst_groups:\
        print("\\n No burst groups found. All images are unique!")\
        return\
        \
    print(f"\\n Found \{len(all_burst_groups)\} burst groups. Analyzing for best pick...")\
    \
    best_picks: Dict[int, Tuple[Path, float]] = \{\}\
    \
    group_iterable = all_burst_groups\
    if TQDM_AVAILABLE:\
        group_iterable = tqdm(all_burst_groups, total=len(all_burst_groups), desc="   Analyzing bursts", unit="burst")\
\
    for i, group in enumerate(group_iterable):\
        best_sharpness = -1.0\
        best_file = None\
        \
        for file_path in group:\
            image_bytes = get_image_bytes_for_analysis(file_path)\
            if image_bytes:\
                scores = analyze_image_quality(image_bytes)\
                sharpness = scores.get('sharpness', 0.0)\
                \
                if sharpness > best_sharpness:\
                    best_sharpness = sharpness\
                    best_file = file_path\
        \
        if best_file:\
            best_picks[i] = (best_file, best_sharpness)\
\
    print(f"\\n Stacking \{len(all_burst_groups)\} burst groups...")\
    \
    for i, group in enumerate(all_burst_groups):\
        folder_name = f"burst-\{i+1:03d\}"\
        folder_path = directory / folder_name\
        \
        print(f"\\n \{folder_name\}/ (\{len(group)\} files)")\
        \
        if not dry_run:\
            folder_path.mkdir(exist_ok=True)\
            \
        winner_data = best_picks.get(i)\
        \
        for file_path in group:\
            if winner_data and file_path == winner_data[0]:\
                new_name = f"\{BEST_PICK_PREFIX\}\{file_path.name\}"\
            else:\
                new_name = file_path.name\
                \
            new_file_path = folder_path / new_name\
            \
            if not dry_run:\
                try:\
                    shutil.move(str(file_path), str(new_file_path))\
                    print(f"    Moved \{file_path.name\}  \{new_name\}")\
                except Exception as e:\
                    print(f"    FAILED to move \{file_path.name\}: \{e\}")\
            else:\
                if winner_data and file_path == winner_data[0]:\
                    print(f"   [PREVIEW] Would move and RENAME \{file_path.name\} to \{new_name\}")\
                else:\
                    print(f"   [PREVIEW] Would move \{file_path.name\} to \{folder_name\}/")\
\
    print("\\n Burst stacking complete!")\
\
\
def analyze_image_quality(image_bytes: bytes) -> Dict[str, float]:\
    """\
    Analyzes image bytes for sharpness and exposure.\
    Core engine reused by cull, burst, and prep features.\
    """\
    scores = \{\
        'sharpness': 0.0,\
        'blacks_pct': 0.0,\
        'whites_pct': 0.0\
    \}\
    try:\
        np_arr = np.frombuffer(image_bytes, np.uint8)\
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\
        \
        if img is None:\
            return scores\
\
        # Sharpness (Laplacian variance)\
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\
        scores['sharpness'] = float(laplacian_var)\
\
        # Exposure (histogram for clipped pixels)\
        total_pixels = gray.size\
        crushed_blacks = np.sum(gray < 10)\
        scores['blacks_pct'] = float(crushed_blacks / total_pixels)\
        blown_whites = np.sum(gray > 245)\
        scores['whites_pct'] = float(blown_whites / total_pixels)\
\
        return scores\
        \
    except Exception:\
        return scores\
\
\
def get_image_bytes_for_analysis(image_path: Path) -> Optional[bytes]:\
    """Helper to get bytes from any supported file"""\
    ext = image_path.suffix.lower()\
    if ext == '.rw2':\
        return convert_raw_to_jpeg(image_path)\
    elif ext in ('.jpg', '.jpeg', '.png'):\
        try:\
            with open(image_path, 'rb') as f:\
                return f.read()\
        except Exception as e:\
            print(f"    Failed to read \{image_path.name\}: \{e\}")\
            return None\
    return None\
\
\
def process_image_for_culling(image_path: Path) -> Tuple[Path, Optional[Dict[str, float]]]:\
    """Thread-pool worker: Gets bytes and runs analysis engine"""\
    image_bytes = get_image_bytes_for_analysis(image_path)\
    if not image_bytes:\
        return image_path, None\
    \
    scores = analyze_image_quality(image_bytes)\
    return image_path, scores\
\
\
def cull_images_in_directory(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """(V6.0) Finds and groups images by technical quality"""\
    \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u55357 \u56785 \u65039   BakLLaVA Photo Organizer --- (Cull Mode)")\
    print(f"\{'='*60\}")\
    print(f" Analyzing technical quality in: \{directory\}")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("     No supported images to analyze. Exiting.")\
        return\
\
    all_scores = \{\}\
    print("\\n  Analyzing sharpness and exposure...")\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_path = \{\
            executor.submit(process_image_for_culling, path): path \
            for path in image_files\
        \}\
        \
        iterable = as_completed(future_to_path)\
        if TQDM_AVAILABLE:\
            iterable = tqdm(iterable, total=len(image_files), desc="   Analyzing", unit="img")\
\
        for future in iterable:\
            path, scores = future.result()\
            if scores:\
                all_scores[path] = scores\
\
    print("\\n  Triaging images into quality tiers...")\
    \
    th = APP_CONFIG['cull_thresholds']\
    tiers = \{"Good": [], "Maybe": [], "Dud": []\}\
    log_data = []\
\
    for path, scores in all_scores.items():\
        sharp = scores['sharpness']\
        blacks = scores['blacks_pct']\
        whites = scores['whites_pct']\
        \
        is_exposure_bad = (blacks > th['exposure_dud_pct']) or (whites > th['exposure_dud_pct'])\
        is_exposure_good = (blacks < th['exposure_good_pct']) and (whites < th['exposure_good_pct'])\
        is_sharp_bad = sharp < th['sharpness_dud']\
        is_sharp_good = sharp > th['sharpness_good']\
\
        tier = "Maybe"\
        if is_sharp_bad or is_exposure_bad:\
            tier = "Dud"\
        elif is_sharp_good and is_exposure_good:\
            tier = "Good"\
        \
        tiers[tier].append(path)\
        log_data.append(\{\
            'file': path.name,\
            'tier': tier,\
            'sharpness': round(sharp, 2),\
            'blacks_pct': round(blacks, 4),\
            'whites_pct': round(whites, 4)\
        \})\
\
    print(f"\\n Found \{len(tiers['Good'])\} Keepers, \{len(tiers['Maybe'])\} Maybes, and \{len(tiers['Dud'])\} Duds.")\
    \
    folder_map = \{\
        "Good": directory / "_Keepers",\
        "Maybe": directory / "_Review_Maybe",\
        "Dud": directory / "_Review_Duds"\
    \}\
    \
    for tier, paths in tiers.items():\
        if not paths:\
            continue\
            \
        folder_path = folder_map[tier]\
        print(f"\\n \{folder_path.name\}/ (\{len(paths)\} files)")\
        \
        if not dry_run:\
            folder_path.mkdir(exist_ok=True)\
            \
        for file_path in paths:\
            new_file_path = folder_path / file_path.name\
            if not dry_run:\
                try:\
                    shutil.move(str(file_path), str(new_file_path))\
                    print(f"    Moved \{file_path.name\}")\
                except Exception as e:\
                    print(f"    FAILED to move \{file_path.name\}: \{e\}")\
            else:\
                print(f"   [PREVIEW] Would move \{file_path.name\} to \{folder_path.name\}/")\
\
    log_file = directory / f"_cull_log_\{SESSION_TIMESTAMP\}.json"\
    \
    try:\
        with open(log_file, 'w') as f:\
            json.dump(\{\
                "session_date": SESSION_TIMESTAMP,\
                "source_directory": str(directory),\
                "thresholds_used": th,\
                "analysis": sorted(log_data, key=lambda x: x['sharpness'])\
            \}, f, indent=2)\
        \
        if dry_run:\
            print(f"\\n [PREVIEW] Calibration log saved: \{log_file.name\}")\
        else:\
            print(f"\\n Cull log saved: \{log_file.name\}")\
            \
    except Exception as e:\
        print(f"\\n FAILED to save log file: \{e\}")\
\
    print("\\n Culling complete!")\
\
\
def prep_smart_export(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """(V6.3) Finds all "Good" tier images and COPIES them to prep folder"""\
    \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u10024  BakLLaVA Photo Organizer --- (Smart Prep Mode)")\
    print(f"\{'='*60\}")\
    print(f" Finding 'Keepers' to copy to: \{PREP_FOLDER_NAME\}/")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("     No supported images to analyze. Exiting.")\
        return\
\
    all_scores = \{\}\
    print("\\n  Analyzing technical quality...")\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_path = \{\
            executor.submit(process_image_for_culling, path): path \
            for path in image_files\
        \}\
        \
        iterable = as_completed(future_to_path)\
        if TQDM_AVAILABLE:\
            iterable = tqdm(iterable, total=len(image_files), desc="   Analyzing", unit="img")\
\
        for future in iterable:\
            path, scores = future.result()\
            if scores:\
                all_scores[path] = scores\
\
    print("\\n  Finding 'Good' tier images...")\
    \
    th = APP_CONFIG['cull_thresholds']\
    good_files = []\
\
    for path, scores in all_scores.items():\
        sharp = scores['sharpness']\
        blacks = scores['blacks_pct']\
        whites = scores['whites_pct']\
        \
        is_exposure_good = (blacks < th['exposure_good_pct']) and (whites < th['exposure_good_pct'])\
        is_sharp_good = sharp > th['sharpness_good']\
\
        if is_sharp_good and is_exposure_good:\
            good_files.append(path)\
\
    if not good_files:\
        print("\\n No 'Keepers' found that meet the 'Good' tier criteria.")\
        print("   (Try adjusting CULL_THRESHOLDS in ~/.photosort.conf if this seems wrong)")\
        return\
\
    print(f"\\n Found \{len(good_files)\} 'Keepers' to copy.")\
    \
    folder_path = directory / PREP_FOLDER_NAME\
    \
    if not dry_run:\
        folder_path.mkdir(exist_ok=True)\
            \
    for file_path in good_files:\
        new_file_path = folder_path / file_path.name\
        if not dry_run:\
            try:\
                shutil.copy2(str(file_path), str(new_file_path))\
                print(f"    Copied \{file_path.name\}")\
            except Exception as e:\
                print(f"    FAILED to copy \{file_path.name\}: \{e\}")\
        else:\
            print(f"   [PREVIEW] Would copy \{file_path.name\} to \{folder_path.name\}/")\
\
    print("\\n Smart Prep complete!")\
\
\
def format_duration(duration: datetime.timedelta) -> str:\
    """Converts timedelta to readable string like '1d 4h 15m'"""\
    total_seconds = int(duration.total_seconds())\
    days, remainder = divmod(total_seconds, 86400)\
    hours, remainder = divmod(remainder, 3600)\
    minutes, _ = divmod(remainder, 60)\
    \
    parts = []\
    if days > 0:\
        parts.append(f"\{days\}d")\
    if hours > 0:\
        parts.append(f"\{hours\}h")\
    if minutes > 0 or (days == 0 and hours == 0):\
        parts.append(f"\{minutes\}m")\
        \
    return " ".join(parts) if parts else "0m"\
\
\
def generate_bar_chart(data: dict, bar_width: int = 25, bar_char: str = "\uc0\u9632 ") -> List[str]:\
    """Generates ASCII bar chart lines from a dictionary"""\
    output_lines = []\
    if not data:\
        return output_lines\
        \
    max_val = max(data.values())\
    if max_val == 0:\
        max_val = 1\
        \
    max_key_len = max(len(key) for key in data.keys())\
    \
    for key, val in data.items():\
        bar_len = int(math.ceil((val / max_val) * bar_width))\
        bar = bar_char * bar_len\
        line = f"   \{key.ljust(max_key_len)\}: \{str(val).ljust(4)\} \{bar\}"\
        output_lines.append(line)\
        \
    return output_lines\
\
\
def analyze_single_exif(image_path: Path) -> Optional[Dict]:\
    """\
    Thread-pool worker: Opens image and extracts key EXIF data.\
    V6.4.2: Intelligently calculates aperture ratios.\
    """\
    try:\
        with open(image_path, 'rb') as f:\
            tags = exifread.process_file(f, details=False, stop_tag='EXIF DateTimeOriginal')\
\
            if not tags or 'EXIF DateTimeOriginal' not in tags:\
                return None\
\
            timestamp_str = str(tags['EXIF DateTimeOriginal'])\
            dt_obj = datetime.strptime(timestamp_str, '%Y:%m:%d %H:%M:%S')\
\
            camera = str(tags.get('Image Model', 'Unknown')).strip()\
            focal_len = str(tags.get('EXIF FocalLength', 'Unknown')).split(' ')[0]\
            \
            aperture_str = "Unknown"\
            aperture_tag = tags.get('EXIF FNumber')\
            \
            if aperture_tag:\
                val = aperture_tag.values[0]\
                \
                if hasattr(val, 'num') and hasattr(val, 'den'):\
                    if val.den == 0:\
                        aperture_val = 0.0\
                    else:\
                        aperture_val = float(val.num) / float(val.den)\
                    aperture_str = f"f/\{aperture_val:.1f\}"\
                else:\
                    aperture_str = f"f/\{val:.1f\}"\
\
            if not camera: camera = "Unknown"\
            if not focal_len: focal_len = "Unknown"\
            if aperture_str == "f/0.0": aperture_str = "Unknown"\
\
            return \{\
                'timestamp': dt_obj,\
                'camera': camera,\
                'focal_length': f"\{focal_len\} mm",\
                'aperture': aperture_str\
            \}\
            \
    except Exception:\
        return None\
\
\
def show_exif_insights(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """(V6.4) Scans images, aggregates EXIF data, prints summary"""\
    \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u55357 \u56522  BakLLaVA Photo Organizer --- (EXIF Stats Mode)")\
    print(f"\{'='*60\}")\
    print(f" Scanning EXIF data in: \{directory\}")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("     No supported images to analyze. Exiting.")\
        return\
\
    all_stats = []\
    print("\\n  Reading EXIF data...")\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_path = \{\
            executor.submit(analyze_single_exif, path): path \
            for path in image_files\
        \}\
        \
        iterable = as_completed(future_to_path)\
        if TQDM_AVAILABLE:\
            iterable = tqdm(iterable, total=len(image_files), desc="   Scanning", unit="img")\
\
        for future in iterable:\
            result_dict = future.result()\
            if result_dict:\
                all_stats.append(result_dict)\
\
    if not all_stats:\
        print(f"\\n  No EXIF data found in \{len(image_files)\} scanned images.")\
        print("   (Files may be JPEGs with stripped metadata)")\
        return\
\
    print(" Aggregating statistics...")\
    \
    timestamps = sorted([s['timestamp'] for s in all_stats])\
    start_time = timestamps[0]\
    end_time = timestamps[-1]\
    duration = end_time - start_time\
    duration_str = format_duration(duration)\
\
    LIGHTING_TABLE = \{\
        (0, 4):   "Night",\
        (5, 7):   "Golden Hour (AM)",\
        (8, 10):  "Morning",\
        (11, 13): "Midday",\
        (14, 16): "Afternoon",\
        (17, 18): "Golden Hour (PM)",\
        (19, 21): "Dusk",\
        (22, 23): "Night",\
    \}\
    \
    lighting_buckets = defaultdict(int)\
    camera_counter = Counter()\
    focal_len_counter = Counter()\
    aperture_counter = Counter()\
\
    for stats in all_stats:\
        hour = stats['timestamp'].hour\
        for (start, end), name in LIGHTING_TABLE.items():\
            if start <= hour <= end:\
                lighting_buckets[name] += 1\
                break\
        \
        camera_counter[stats['camera']] += 1\
        focal_len_counter[stats['focal_length']] += 1\
        aperture_counter[stats['aperture']] += 1\
\
    log_file_path = directory / f"_exif_summary_\{SESSION_TIMESTAMP\}.json"\
    \
    json_report = \{\
        "session_story": \{\
            "start_time": start_time.isoformat(),\
            "end_time": end_time.isoformat(),\
            "duration_str": duration_str,\
            "total_images_scanned": len(image_files),\
            "images_with_exif": len(all_stats)\
        \},\
        "lighting_distribution": dict(lighting_buckets),\
        "gear_used": \{\
            "cameras": dict(camera_counter),\
        \},\
        "habits": \{\
            "focal_lengths": dict(focal_len_counter),\
            "apertures": dict(aperture_counter),\
        \}\
    \}\
    \
    try:\
        with open(log_file_path, 'w') as f:\
            json.dump(json_report, f, indent=2)\
    except Exception as e:\
        print(f"\\n  Warning: Could not save JSON log: \{e\}")\
\
    header = f"EXIF INSIGHTS: \{directory.name\}"\
    print(f"\\n\{'='*60\}")\
    print(f"\{header:^60\}")\
    print(f"\{'='*60\}")\
    \
    print(" \uc0\u55357 \u56534  Session Story:")\
    print(f"   Started:     \{start_time.strftime('%a, %b %d %Y at %I:%M %p')\}")\
    print(f"   Ended:       \{end_time.strftime('%a, %b %d %Y at %I:%M %p')\}")\
    print(f"   Duration:    \{duration_str\}")\
    print(f"   Total Shots: \{len(image_files)\} (\{len(all_stats)\} with EXIF data)")\
    print(f"\{'-'*60\}")\
\
    print(" \uc0\u9728 \u65039  Lighting Conditions:")\
    bar_lines = generate_bar_chart(lighting_buckets, bar_width=30)\
    for line in bar_lines:\
        print(line)\
    \
    print("\\n \uc0\u55356 \u57256  Creative Habits (Top 3):")\
        \
    print("\\n    Cameras:")\
    for camera, count in camera_counter.most_common(3):\
        print(f"      \'95 \{camera\}: \{count\}")\
\
    print("\\n    Focal Lengths (Composition):")\
    for focal, count in focal_len_counter.most_common(3):\
        print(f"      \'95 \{focal\}: \{count\}")\
        \
    print("\\n    Apertures (Depth of Field):")\
    for aperture, count in aperture_counter.most_common(3):\
        print(f"      \'95 \{aperture\}: \{count\}")\
\
    print(f"\\n\{'='*60\}")\
    print(f" Summary saved to: \{log_file_path.name\}")\
\
\
def get_ingest_config(APP_CONFIG: dict) -> Tuple[Path, str]:\
    """\
    V6.5: Helper function to get destination and model from user.\
    V7.0: Reads defaults from APP_CONFIG.\
    Returns (destination_path, model_name).\
    """\
    default_dest = APP_CONFIG['default_destination']\
    default_model = APP_CONFIG['default_model']\
\
    print(f"\\n \uc0\u55357 \u56770 \u65039   Default archive destination: \{default_dest\}")\
    new_dest_path = input("   Press ENTER to use default, or type a new path: ").strip()\
    \
    chosen_destination: Path\
    if not new_dest_path:\
        chosen_destination = default_dest\
        print(f"    Using default destination.")\
    else:\
        chosen_destination = Path(new_dest_path).expanduser()\
        print(f"    Using: \{chosen_destination\}")\
    \
    try:\
        chosen_destination.mkdir(parents=True, exist_ok=True)\
    except Exception as e:\
        print(f" \uc0\u10060  Error creating destination folder: \{e\}")\
        print("   Please check the path and permissions. Exiting.")\
        sys.exit(1)\
    \
    print(f"\\n \uc0\u55358 \u56598  Default model: \{default_model\}")\
    available_models = get_available_models()\
    \
    if available_models is None:\
        print("\\n \uc0\u10060  FATAL: Could not connect to Ollama server.")\
        print("   Please ensure Ollama is running.")\
        sys.exit(1)\
    \
    if available_models:\
        print(f"   Available models: \{', '.join(available_models)\}")\
    else:\
        print("     No models found. Run 'ollama pull bakllava' to install one.")\
    \
    new_model = input("   Press ENTER to use default, or type a model name: ").strip()\
    \
    chosen_model: str\
    if not new_model:\
        chosen_model = default_model\
        print(f"    Using default model.")\
    else:\
        if available_models and new_model not in available_models:\
            print(f"     Warning: '\{new_model\}' not found in available models.")\
            print(f"   Available: \{', '.join(available_models)\}")\
            confirm = input("   Continue anyway? (y/n): ").strip().lower()\
            if confirm != 'y':\
                print("Cancelled.")\
                sys.exit(0)\
        chosen_model = new_model\
        print(f"    Using model: \{chosen_model\}")\
    \
    return chosen_destination, chosen_model\
\
\
def auto_workflow(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """\
    (V6.5) Fully automated workflow: Stack  Cull  AI-Name  Archive.\
    V6.5 Update: Asks for config FIRST, then shows stats, then processes.\
    """\
    \
    print("\\n" + "="*60)\
    print(" \uc0\u55357 \u56960  BakLLaVA Photo Organizer --- (Auto Mode)")\
    print("="*60)\
    print("This will automatically Stack, Cull, AI-Name, and Archive")\
    print("all 'hero' photos from this session.")\
    print("-"*60)\
\
    # V6.5 FIX: Ask for configuration FIRST\
    print("\\n Step 1/5: Configuration")\
    chosen_destination, chosen_model = get_ingest_config(APP_CONFIG)\
\
    # Step 2: Stats Preview (read-only)\
    print("\\n Step 2/5: Analyzing session (read-only)...")\
    try:\
        show_exif_insights(directory, dry_run=True, APP_CONFIG=APP_CONFIG, max_workers=max_workers)\
    except Exception as e:\
        print(f"     Could not run EXIF analysis: \{e\}")\
\
    # Confirmation gate\
    print("-"*60)\
    print(f"\\n Source:      \{directory\}")\
    print(f" Destination: \{chosen_destination\}")\
    print(f" Model:       \{chosen_model\}")\
    confirm = input(f"\\n  Ready to process? (y/n): ")\
    if confirm.lower() != 'y':\
        print("Cancelled.")\
        return\
\
    # Step 3: Group Bursts\
    print("\\n Step 3/5: Stacking burst shots...")\
    group_bursts_in_directory(directory, dry_run=False, APP_CONFIG=APP_CONFIG, max_workers=max_workers)\
\
    # Step 4: Cull Singles\
    print("\\n Step 4/5: Culling single shots...")\
    cull_images_in_directory(directory, dry_run=False, APP_CONFIG=APP_CONFIG, max_workers=max_workers)\
\
    # V6.5 VALIDATION: Check if we have any keepers\
    keepers_dir = directory / "_Keepers"\
    if not keepers_dir.exists() or not any(keepers_dir.iterdir()):\
        print("\\n  Warning: No '_Keepers' folder found or it's empty.")\
        print("   Cull may have failed or all images were duds.")\
\
    # Step 5: Find and AI-name hero files\
    print("\\n Step 5/5: Finding and archiving 'hero' files...")\
    \
    hero_files = []\
    \
    # Get keepers\
    if keepers_dir.is_dir():\
        for f in keepers_dir.iterdir():\
            if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS:\
                hero_files.append(f)\
    \
    # Get picks from bursts\
    for burst_folder in directory.glob("burst-*/"):\
        if burst_folder.is_dir():\
            for f in burst_folder.iterdir():\
                if f.is_file() and f.name.startswith(BEST_PICK_PREFIX):\
                    hero_files.append(f)\
\
    if not hero_files:\
        print("\\n  No 'Keepers' or '_PICK_' files found. Nothing to archive.")\
        print("   Auto workflow complete.")\
        return\
\
    print(f"   Found \{len(hero_files)\} 'hero' files to AI-name and archive.")\
    \
    results = \{"success": [], "failed": []\}\
    \
    if TQDM_AVAILABLE:\
        pbar = tqdm(total=len(hero_files), desc=" \uc0\u55358 \u56598  Archiving", unit="img", ncols=80)\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_file = \{\
            executor.submit(process_single_image, img_path, chosen_destination, chosen_model, dry_run=False): img_path \
            for img_path in hero_files\
        \}\
        \
        for future in as_completed(future_to_file):\
            original, success, message, description = future.result()\
            \
            if success:\
                results["success"].append(\{\
                    "original": original.name,\
                    "new_name": message,\
                    "description": description\
                \})\
            else:\
                results["failed"].append((original.name, message))\
                if TQDM_AVAILABLE:\
                    pbar.write(f" \uc0\u10060  \{original.name\}: \{message\}")\
            \
            if TQDM_AVAILABLE:\
                pbar.update(1)\
    \
    if TQDM_AVAILABLE:\
        pbar.close()\
        \
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u9989  Successfully archived: \{len(results['success'])\}")\
    print(f" \uc0\u10060  Failed to archive: \{len(results['failed'])\}")\
\
    if results["success"]:\
        organize_into_folders(results["success"], chosen_destination, dry_run=False)\
\
    print("\\n" + "="*60)\
    print(" \uc0\u55357 \u56960  AUTO WORKFLOW COMPLETE")\
    print("="*60)\
    print(f" Your 'hero' photos are now in: \{chosen_destination\}")\
    print(f"  Remaining 'duds' and 'bursts' are in: \{directory\}")\
\
\
def critique_images_in_directory(directory: Path, dry_run: bool, APP_CONFIG: dict, max_workers: int = MAX_WORKERS):\
    """\
    (V7.0) Generates artistic critiques for images.\
    Saves JSON sidecar files next to each image.\
    """\
    \
    print("\\n" + "="*60)\
    print(" \uc0\u55356 \u57256  BakLLaVA Photo Organizer --- (AI Critic Mode)")\
    print("="*60)\
    \
    model_name = APP_CONFIG['critique_model']\
    print(f" Analyzing images in: \{directory\}")\
    print(f" Using Creative Director model: \{model_name\}")\
    print(f" Output: .json sidecar files (e.g., photo.json)")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("     No supported images to analyze. Exiting.")\
        return\
\
    # Find files that *don't* have a .json sidecar yet\
    files_to_critique = []\
    for f in image_files:\
        if not f.with_suffix('.json').exists():\
            files_to_critique.append(f)\
    \
    if not files_to_critique:\
        print(f"\\n All \{len(image_files)\} images already have .json critiques. All done!")\
        return\
\
    print(f"\\n Found \{len(files_to_critique)\} new images to critique (skipping \{len(image_files) - len(files_to_critique)\} already done).")\
    \
    if dry_run:\
        print("\\n [PREVIEW] Would analyze the following files:")\
        for f in files_to_critique:\
            print(f"   \'95 \{f.name\}")\
        print("\\n [PREVIEW] Dry run complete. No critiques were generated.")\
        return\
\
    results = \{"success": 0, "failed": 0, "invalid_json": 0\}\
    \
    if TQDM_AVAILABLE:\
        pbar = tqdm(total=len(files_to_critique), desc=" \uc0\u55356 \u57256  Critiquing", unit="img", ncols=80)\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_file = \{\
            executor.submit(get_ai_critique, img_path, model_name): img_path \
            for img_path in files_to_critique\
        \}\
        \
        for future in as_completed(future_to_file):\
            img_path = future_to_file[future]\
            json_string = future.result()\
            json_path = img_path.with_suffix('.json')\
\
            if not json_string:\
                results["failed"] += 1\
                if TQDM_AVAILABLE:\
                    pbar.write(f" \uc0\u10060  \{img_path.name\}: Failed (No response from model)")\
                continue\
\
            try:\
                # Clean up potential markdown fences\
                if json_string.startswith("```json"):\
                    json_string = json_string.strip("```json\\n")\
                if json_string.endswith("```"):\
                    json_string = json_string.strip("```\\n")\
                \
                data = json.loads(json_string)\
                \
                with open(json_path, 'w') as f:\
                    json.dump(data, f, indent=2)\
                \
                results["success"] += 1\
\
            except json.JSONDecodeError:\
                results["invalid_json"] += 1\
                if TQDM_AVAILABLE:\
                    pbar.write(f" \uc0\u10060  \{img_path.name\}: Failed (Model returned invalid JSON)")\
                # Save the bad response for debugging\
                with open(img_path.with_suffix('.bad.json'), 'w') as f:\
                    f.write(json_string)\
            except Exception as e:\
                results["failed"] += 1\
                if TQDM_AVAILABLE:\
                    pbar.write(f" \uc0\u10060  \{img_path.name\}: Failed (\{e\})")\
\
            if TQDM_AVAILABLE:\
                pbar.update(1)\
\
    if TQDM_AVAILABLE:\
        pbar.close()\
\
    print(f"\\n\{'='*60\}")\
    print(" \uc0\u55356 \u57256  Critique Complete")\
    print(f"   Successfully generated: \{results['success']\}")\
    print(f"   Invalid JSON returned:  \{results['invalid_json']\}")\
    print(f"   Failed (no response):   \{results['failed']\}")\
    print("="*60)\
    print(f" JSON sidecar files are saved in: \{directory\}")\
\
\
def run_default_ingest(current_dir: Path, dry_run: bool, APP_CONFIG: dict):\
    """Runs the original V4.1 AI-powered ingest process"""\
    print(f"\\n\{'='*60\}")\
    print(f" \uc0\u55358 \u56598  BakLLaVA Photo Organizer --- (Legacy Ingest Mode)")\
    print(f"\{'='*60\}")\
    print(f" Current directory: \{current_dir\}")\
    \
    chosen_destination, chosen_model = get_ingest_config(APP_CONFIG)\
\
    response = input("\\n  Process all images in this directory? (y/n): ")\
    if response.lower() != 'y':\
        print("Cancelled.")\
        return\
    \
    process_directory(current_dir, chosen_destination, chosen_model, dry_run)\
\
\
def main():\
    """Main entry point"""\
    \
    # V7.0: Load config from file or use defaults\
    APP_CONFIG = load_app_config()\
\
    current_dir = Path.cwd()\
    args = set(sys.argv[1:])\
    \
    dry_run = "--preview" in args or "-p" in args\
    \
    # V7.0: Updated dispatch table with --critique\
    DISPATCH_TABLE = \{\
        '--auto': (auto_workflow, V5_LIBS_AVAILABLE and V6_CULL_LIBS_AVAILABLE, V5_LIBS_MSG if not V5_LIBS_AVAILABLE else V6_LIBS_MSG),\
        '--group-bursts': (group_bursts_in_directory, V5_LIBS_AVAILABLE, V5_LIBS_MSG),\
        '-b': (group_bursts_in_directory, V5_LIBS_AVAILABLE, V5_LIBS_MSG),\
        '--cull': (cull_images_in_directory, V6_CULL_LIBS_AVAILABLE, V6_LIBS_MSG),\
        '-c': (cull_images_in_directory, V6_CULL_LIBS_AVAILABLE, V6_LIBS_MSG),\
        '--prep': (prep_smart_export, V6_CULL_LIBS_AVAILABLE, V6_LIBS_MSG),\
        '--pe': (prep_smart_export, V6_CULL_LIBS_AVAILABLE, V6_LIBS_MSG),\
        '--stats': (show_exif_insights, V6_4_EXIF_LIBS_AVAILABLE, V6_4_LIBS_MSG),\
        '--exif': (show_exif_insights, V6_4_EXIF_LIBS_AVAILABLE, V6_4_LIBS_MSG),\
        '--critique': (critique_images_in_directory, V5_LIBS_AVAILABLE, V5_LIBS_MSG), # V7.0\
        '--art': (critique_images_in_directory, V5_LIBS_AVAILABLE, V5_LIBS_MSG),      # V7.0\
    \}\
    \
    command_to_run = None\
    for flag in args:\
        if flag in DISPATCH_TABLE:\
            command_to_run = flag\
            break\
            \
    if command_to_run:\
        (func_to_call, libs_ok, lib_msg) = DISPATCH_TABLE[command_to_run]\
        \
        if not libs_ok:\
            print(lib_msg)\
            return\
            \
        if dry_run and command_to_run not in ('--auto',):\
             print("\\n" + "="*60)\
             print(f"  DRY RUN: \{command_to_run.upper()\} PREVIEW MODE")\
             print(" NO FILES WILL BE MOVED/COPIED/WRITTEN")\
             print("="*60)\
        \
        # V7.0: Pass APP_CONFIG to the dispatched function\
        func_to_call(current_dir, dry_run, APP_CONFIG)\
\
    else:\
        if "--help" in args or "-h" in args:\
             print("\\n \uc0\u55357 \u56764 \u65039   BakLLaVA Photo Organizer - Usage")\
             print(f"\\n Config file loaded from: \{CONFIG_FILE_PATH\} (if it exists)")\
             print("\\nCommands:")\
             print("  --auto           : (RECOMMENDED) Full automated workflow: Stack  Cull  AI-Archive")\
             print("  <no command>     : (Legacy) AI Ingest on ALL files in current directory")\
             print("\\nManual Tools:")\
             print("  --critique, --art: (V7.0) Run AI 'Creative Director' on a folder, save .json sidecars")\
             print("  --stats, --exif  : Display EXIF insights dashboard")\
             print("  --group-bursts, -b : Stack visually similar burst shots, mark best pick")\
             print("  --cull, -c       : Sort images into _Keepers, _Review_Maybe, _Review_Duds")\
             print("  --prep, --pe     : Find 'Good' images and copy to _ReadyForLightroom")\
             print("\\nOptions:")\
             print("  --preview, -p    : Dry run mode (no files moved/copied/written)")\
             print("  --help, -h       : Show this help message")\
             return\
\
        if dry_run:\
            print("\\n" + "="*60)\
            print(" DRY RUN: LEGACY INGEST PREVIEW MODE")\
            print(" NO FILES WILL BE MOVED")\
            print("="*60)\
        \
        # V7.0: Pass APP_CONFIG to the default ingest\
        run_default_ingest(current_dir, dry_run, APP_CONFIG)\
    \
    if dry_run and command_to_run not in ('--auto',):\
         print("\\n" + "="*60)\
         print(" DRY RUN COMPLETE - NO FILES WERE MOVED/COPIED/WRITTEN")\
         print("="*60)\
    else:\
        print("\\n Done!\\n")\
\
\
if __name__ == "__main__":\
    main()}