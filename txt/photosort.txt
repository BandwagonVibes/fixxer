{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 #!/usr/bin/env python3\
"""\
BakLLaVA Photo Organizer\
Renames photos using local vision model and organizes into smart groups.\
\
V5.0 (Burst Stacker) Update:\
- Adds '--group-bursts' / '-b' flag to find and group visually similar images.\
- This is a *new, separate* command from the main ingest.\
- Requires 'pip install imagehash'\
"""\
\
import os\
import json\
import base64\
import requests\
import shutil\
import tempfile\
from pathlib import Path\
from datetime import datetime\
from concurrent.futures import ThreadPoolExecutor, as_completed\
from typing import Optional, Tuple, List, Dict\
from collections import defaultdict\
import re\
import subprocess\
import sys\
\
# --- V5.0: NEW IMPORT ---\
# We need the 'imagehash' library and PIL (Pillow) to create 'visual fingerprints'\
try:\
    import imagehash\
    from PIL import Image, ImageFile\
    # Allow PIL to load truncated images, which can happen with RAW previews\
    ImageFile.LOAD_TRUNCATED_IMAGES = True\
    V5_LIBS_AVAILABLE = True\
except ImportError:\
    V5_LIBS_AVAILABLE = False\
\
# Try to import tqdm for progress bar\
try:\
    from tqdm import tqdm\
    TQDM_AVAILABLE = True\
except ImportError:\
    TQDM_AVAILABLE = False\
    print("\uc0\u55357 \u56481  Tip: Install tqdm for progress bars: pip3 install tqdm")\
\
# Check if dcraw is available for RAW support\
def check_dcraw():\
    """Check if dcraw is available"""\
    try:\
        result = subprocess.run(['which', 'dcraw'], capture_output=True, text=True)\
        return result.returncode == 0 and result.stdout.strip()\
    except Exception:\
        return False\
\
RAW_SUPPORT = check_dcraw()\
\
# --- Configuration ---\
OLLAMA_URL = "http://localhost:11434/api/chat"\
DEFAULT_MODEL_NAME = "bakllava"\
DEFAULT_DESTINATION_BASE = Path.home() / "Library/Mobile Documents/com~apple~CloudDocs/negatives"\
\
SUPPORTED_EXTENSIONS = \{'.jpg', '.jpeg', '.png'\}\
if RAW_SUPPORT:\
    SUPPORTED_EXTENSIONS.add('.rw2')\
MAX_WORKERS = 5\
TIMEOUT = 60  # seconds per image\
\
# Session date for organizing this batch\
SESSION_DATE = datetime.now().strftime("%Y-%m-%d")\
SESSION_TIMESTAMP = datetime.now().strftime("%Y-%m-%d_%H%M")\
\
# Keywords for grouping (you can customize these!)\
GROUP_KEYWORDS = \{\
    "Architecture": ["building", "architecture", "structure", "facade", "construction", "tower", "bridge", "monument"],\
    "Street-Scenes": ["street", "road", "sidewalk", "crosswalk", "traffic", "urban", "city"],\
    "People": ["people", "person", "man", "woman", "child", "crowd", "pedestrian", "walking"],\
    "Nature": ["tree", "forest", "mountain", "lake", "river", "ocean", "beach", "sunset", "sunrise", "sky", "cloud"],\
    "Transportation": ["car", "bus", "train", "trolley", "vehicle", "bicycle", "scooter", "motorcycle"],\
    "Signs-Text": ["sign", "text", "billboard", "poster", "graffiti", "writing"],\
    "Food-Dining": ["food", "restaurant", "cafe", "produce", "market", "vendor", "stand"],\
    "Animals": ["dog", "cat", "bird", "animal", "pet"],\
    "Interior": ["interior", "room", "inside", "indoor"],\
\}\
\
# --- V5.0: NEW CONFIGURATION ---\
# How "similar" do images need to be to be "stacked"?\
# 0 = identical. 5 = very similar. 10 = kinda similar.\
BURST_SIMILARITY_THRESHOLD = 8\
\
\
def get_available_models() -> Optional[List[str]]:\
    """\
    Get list of available Ollama models.\
    --- V4.1 FIX ---\
    Returns None if Ollama is unavailable, for a "fail fast" check.\
    """\
    try:\
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, check=True)\
        # Parse output - skip header line, extract model names\
        lines = result.stdout.strip().split('\\n')[1:]  # Skip header\
        models = [line.split()[0] for line in lines if line.strip()]\
        return models\
    except subprocess.CalledProcessError:\
        return None  # Ollama command failed (e.g., server not running)\
    except FileNotFoundError:\
        return None  # Ollama not installed\
    except Exception:\
        return None  # Any other error\
\
\
def convert_raw_to_jpeg(raw_path: Path) -> Optional[bytes]:\
    """Convert RAW file to JPEG bytes using dcraw"""\
    if not RAW_SUPPORT:\
        return None\
    \
    try:\
        # Create temporary file for JPEG output\
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:\
            tmp_jpg = tmp.name\
        \
        # Use dcraw to convert: -c writes to stdout, -w use camera white balance, -q 3 = high quality\
        result = subprocess.run(\
            ['dcraw', '-c', '-w', '-q', '3', str(raw_path)],\
            capture_output=True,\
            check=True\
        )\
        \
        # dcraw outputs PPM to stdout, convert to JPEG using sips (built into macOS)\
        with tempfile.NamedTemporaryFile(suffix='.ppm', delete=False) as ppm_tmp:\
            ppm_tmp.write(result.stdout)\
            ppm_file = ppm_tmp.name\
        \
        # Convert PPM to JPEG using sips\
        subprocess.run(\
            ['sips', '-s', 'format', 'jpeg', ppm_file, '--out', tmp_jpg],\
            capture_output=True,\
            check=True\
        )\
        \
        # Read the JPEG\
        with open(tmp_jpg, 'rb') as f:\
            jpeg_bytes = f.read()\
        \
        # Clean up temp files\
        os.unlink(ppm_file)\
        os.unlink(tmp_jpg)\
        \
        return jpeg_bytes\
    \
    except Exception as e:\
        print(f"\uc0\u10060  Error converting RAW file: \{e\}")\
        # Clean up on error\
        try:\
            if 'ppm_file' in locals():\
                os.unlink(ppm_file)\
            if 'tmp_jpg' in locals() and os.path.exists(tmp_jpg):\
                os.unlink(tmp_jpg)\
        except:\
            pass\
        return None\
\
\
def encode_image(image_path: Path) -> Optional[str]:\
    """Convert image to base64 string, handling RAW files"""\
    try:\
        # Handle RAW files\
        if image_path.suffix.lower() == '.rw2':\
            jpeg_bytes = convert_raw_to_jpeg(image_path)\
            if jpeg_bytes:\
                return base64.b64encode(jpeg_bytes).decode('utf-8')\
            else:\
                return None\
        \
        # Handle regular image files\
        with open(image_path, 'rb') as img_file:\
            return base64.b64encode(img_file.read()).decode('utf-8')\
    \
    except Exception as e:\
        print(f"\uc0\u10060  Error encoding \{image_path.name\}: \{e\}")\
        return None\
\
# --- V5.0: NEW HELPER FUNCTION ---\
def get_image_hash(image_path: Path) -> Optional[tuple[Path, imagehash.ImageHash]]:\
    """\
    Calculates the perceptual hash (visual fingerprint) of a single image.\
    This function is designed to be run in a thread pool.\
    """\
    # For RAW files, we generate the hash on the *preview* JPEG,\
    # which is much faster than a full `dcraw` conversion.\
    if image_path.suffix.lower() in ['.rw2', '.cr2', '.nef', '.arw', '.dng']:\
        try:\
            # Use dcraw to extract the *embedded* thumbnail. It's fast.\
            # -e = extract thumbnail, -c = write to stdout\
            result = subprocess.run(\
                ['dcraw', '-e', '-c', str(image_path)],\
                capture_output=True,\
                check=True\
            )\
            # Load the thumbnail data from stdout into PIL\
            with tempfile.NamedTemporaryFile() as tmp:\
                tmp.write(result.stdout)\
                tmp.seek(0)\
                # sips can convert the .ppm thumbnail to a .png PIL can read\
                with tempfile.NamedTemporaryFile(suffix='.png') as png_tmp:\
                    subprocess.run(\
                        ['sips', '-s', 'format', 'png', tmp.name, '--out', png_tmp.name],\
                        capture_output=True,\
                        check=True\
                    )\
                    with Image.open(png_tmp.name) as img:\
                        return image_path, imagehash.phash(img)\
        except Exception:\
            # Fallback: if thumbnail fails, just skip hashing this file\
            return image_path, None\
            \
    # For regular JPG/PNG files, just open them\
    try:\
        with Image.open(image_path) as img:\
            return image_path, imagehash.phash(img)\
    except Exception as e:\
        # Catch corrupt images\
        print(f"   \uc0\u9888 \u65039   Skipping hash for \{image_path.name\}: \{e\}")\
        return image_path, None\
# --- END NEW FUNCTION ---\
\
\
def get_ai_description(image_path: Path, model_name: str) -> Optional[str]:\
    """Get filename suggestion from vision model"""\
    base64_image = encode_image(image_path)\
    if not base64_image:\
        return None\
    \
    payload = \{\
        "model": model_name,\
        "messages": [\
            \{\
                "role": "user",\
                "content": "What is in this image? Describe it concisely for a file name.",\
                "images": [base64_image]\
            \}\
        ],\
        "stream": False\
    \}\
    \
    try:\
        response = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)\
        response.raise_for_status()\
        \
        result = response.json()\
        description = result['message']['content'].strip()\
        \
        return description\
        \
    except requests.exceptions.Timeout:\
        print(f"\uc0\u9201 \u65039   Timeout processing \{image_path.name\}")\
        return None\
    except Exception as e:\
        print(f"\uc0\u10060  Error processing \{image_path.name\}: \{e\}")\
        return None\
\
\
def clean_filename(description: str) -> str:\
    """Convert AI description to clean filename"""\
    # Remove quotes, periods, and other punctuation\
    clean = description.strip('"\\'.,!?')\
    \
    # Replace spaces and special chars with hyphens\
    clean = re.sub(r'[^\\w\\s-]', '', clean)\
    clean = re.sub(r'[-\\s]+', '-', clean)\
    \
    # Lowercase and limit length\
    clean = clean.lower()[:60]\
    \
    return clean.strip('-')\
\
\
def get_unique_filename(base_name: str, extension: str, destination: Path) -> Path:\
    """Generate unique filename if file already exists"""\
    filename = destination / f"\{base_name\}\{extension\}"\
    \
    if not filename.exists():\
        return filename\
    \
    # Add counter if file exists\
    counter = 1\
    while True:\
        filename = destination / f"\{base_name\}-\{counter:02d\}\{extension\}"\
        if not filename.exists():\
            return filename\
        counter += 1\
\
\
def categorize_description(description: str) -> str:\
    """Determine category based on keywords in description"""\
    description_lower = description.lower()\
    \
    # Count matches for each category\
    category_scores = \{\}\
    for category, keywords in GROUP_KEYWORDS.items():\
        score = sum(1 for keyword in keywords if keyword in description_lower)\
        if score > 0:\
            category_scores[category] = score\
    \
    # Return category with highest score, or "Misc" if no matches\
    if category_scores:\
        return max(category_scores, key=category_scores.get)\
    return "Miscellaneous"\
\
\
def process_single_image(image_path: Path, destination_base: Path, model_name: str, dry_run: bool) -> Tuple[Path, bool, str, str]:\
    """Process one image: get description, rename, move to temp location"""\
    try:\
        # Get AI description\
        # A dry run still hits the AI, so you can preview the *real* names\
        description = get_ai_description(image_path, model_name)\
        if not description:\
            return image_path, False, "Failed to get AI description", ""\
        \
        # Clean filename\
        clean_name = clean_filename(description)\
        if not clean_name:\
            clean_name = f"image-\{datetime.now().strftime('%Y%m%d-%H%M%S')\}"\
        \
        # Get unique destination path\
        extension = image_path.suffix.lower()\
        new_path = get_unique_filename(clean_name, extension, destination_base)\
        \
        # --- V4.1 DRY RUN LOGIC ---\
        if not dry_run:\
            # This is a REAL run. Move the file.\
            shutil.move(str(image_path), str(new_path))\
        # In a dry run, we do *not* move the file. We just fall through.\
        # We will print the *intended* action in the organize_into_folders function.\
        \
        return image_path, True, new_path.name, description\
        \
    except Exception as e:\
        return image_path, False, str(e), ""\
\
\
def organize_into_folders(processed_files: List[Dict], destination_base: Path, dry_run: bool):\
    """Group files into folders based on their descriptions"""\
    print(f"\\n\{'='*60\}")\
    print("\uc0\u55357 \u56513  Organizing into smart folders...")\
    print(f"\{'='*60\}\\n")\
    \
    # Categorize each file\
    categories = defaultdict(list)\
    for file_info in processed_files:\
        filename = file_info['new_name']\
        description = file_info['description']\
        category = categorize_description(description)\
        categories[category].append(\{\
            'filename': filename,\
            'description': description\
        \})\
    \
    # Create folders and move files\
    for category, files in categories.items():\
        folder_name = f"\{SESSION_DATE\}_\{category\}"\
        folder_path = destination_base / folder_name\
        \
        # --- V4.1 DRY RUN LOGIC ---\
        if not dry_run:\
            folder_path.mkdir(exist_ok=True)\
        \
        print(f"\uc0\u55357 \u56514  \{folder_name\}/ (\{len(files)\} files)")\
        \
        for file_info in files:\
            src = destination_base / file_info['filename']\
            dst = folder_path / file_info['filename']\
            \
            # --- V4.1 DRY RUN LOGIC ---\
            if not dry_run:\
                if src.exists():\
                    shutil.move(str(src), str(dst))\
                    print(f"   \uc0\u8594  \{file_info['filename']\}")\
            else:\
                # Just print what we *would* do\
                print(f"   [PREVIEW] Would move \{file_info['filename']\} here")\
    \
    print(f"\\n\uc0\u10024  Organized into \{len(categories)\} folders")\
\
\
def process_directory(directory: Path, destination_base: Path, model_name: str, dry_run: bool, max_workers: int = MAX_WORKERS):\
    """Process all images in directory with concurrent workers"""\
    \
    # Find all supported images\
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if not image_files:\
        print("\uc0\u9888 \u65039   No supported image files found in current directory")\
        print(f"   Looking for: \{', '.join(SUPPORTED_EXTENSIONS)\}")\
        return\
    \
    print(f"\\n\uc0\u55357 \u56568  Found \{len(image_files)\} images to process")\
    print(f"\uc0\u55356 \u57263  Destination: \{destination_base\}")\
    print(f"\uc0\u55358 \u56598  Model: \{model_name\}")\
    print(f"\uc0\u9881 \u65039   Using \{max_workers\} concurrent workers")\
    if RAW_SUPPORT:\
        print("\uc0\u9989  RAW support enabled (dcraw)")\
    print(f"\{'='*60\}\\n")\
    \
    # Phase 1: Process with thread pool (rename and move to destination root)\
    results = \{"success": [], "failed": []\}\
    \
    # Create progress bar if tqdm is available\
    if TQDM_AVAILABLE:\
        pbar = tqdm(total=len(image_files), desc="\uc0\u55356 \u57256  Processing images", unit="img", ncols=80)\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        future_to_file = \{\
            # Pass model_name and dry_run to the worker\
            executor.submit(process_single_image, img, destination_base, model_name, dry_run): img \
            for img in image_files\
        \}\
        \
        for future in as_completed(future_to_file):\
            original, success, message, description = future.result()\
            \
            if success:\
                results["success"].append(\{\
                    "original": original.name,\
                    "new_name": message,\
                    "description": description\
                \})\
            else:\
                results["failed"].append((original.name, message))\
                if TQDM_AVAILABLE:\
                    pbar.write(f"\uc0\u10060  \{original.name\}: \{message\}")\
                else:\
                    print(f"\uc0\u10060  \{original.name\}: \{message\}")\
            \
            # Update progress bar\
            if TQDM_AVAILABLE:\
                pbar.update(1)\
    \
    # Close progress bar\
    if TQDM_AVAILABLE:\
        pbar.close()\
    \
    # Print processing summary\
    print(f"\\n\{'='*60\}")\
    print(f"\uc0\u9989  Successfully processed: \{len(results['success'])\}")\
    print(f"\uc0\u10060  Failed: \{len(results['failed'])\}")\
    \
    if results["failed"]:\
        print("\\n\uc0\u9888 \u65039   Failed files:")\
        for orig, reason in results["failed"]:\
            print(f"   \'95 \{orig\}: \{reason\}")\
    \
    # Phase 2: Organize into folders\
    if results["success"]:\
        organize_into_folders(results["success"], destination_base, dry_run)\
    \
    # Save log\
    log_file = destination_base / f"_import_log_\{SESSION_TIMESTAMP\}.json"\
    \
    # --- V4.1 DRY RUN LOGIC ---\
    if not dry_run:\
        with open(log_file, 'w') as f:\
            json.dump(\{\
                "session_date": SESSION_TIMESTAMP,\
                "source_directory": str(directory),\
                "destination_directory": str(destination_base),\
                "model_used": model_name,\
                "total_files": len(image_files),\
                "successful": results["success"],\
                "failed": [\{"original": o, "reason": r\} for o, r in results["failed"]],\
            \}, f, indent=2)\
        \
        print(f"\\n\uc0\u55357 \u56541  Log saved: \{log_file.name\}")\
    else:\
        print(f"\\n[PREVIEW] Would save log file to: \{log_file.name\}")\
\
\
# --- V5.0: NEW "BURST STACKER" FUNCTION ---\
def group_bursts_in_directory(directory: Path, dry_run: bool, max_workers: int = MAX_WORKERS):\
    """Finds and groups visually similar images into subfolders."""\
    \
    print(f"\\n\uc0\u55356 \u57256  BakLLaVA Photo Organizer --- (Burst Stacker Mode)")\
    print(f"\uc0\u55357 \u56568  Scanning for visually similar images in: \{directory\}")\
    print(f"   (Similarity threshold set to: \{BURST_SIMILARITY_THRESHOLD\})")\
    \
    image_files = [\
        f for f in directory.iterdir() \
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS\
    ]\
    \
    if len(image_files) < 2:\
        print("   Not enough images to compare. Exiting.")\
        return\
\
    # --- Step 1: Calculate all hashes in parallel (FAST) ---\
    all_hashes = \{\}\
    print("\\n\uc0\u55357 \u56620  Calculating visual fingerprints...")\
    \
    with ThreadPoolExecutor(max_workers=max_workers) as executor:\
        # Create a map of futures\
        future_to_path = \{executor.submit(get_image_hash, path): path for path in image_files\}\
        \
        # Set up progress bar\
        iterable = as_completed(future_to_path)\
        if TQDM_AVAILABLE:\
            iterable = tqdm(iterable, total=len(image_files), desc="   Hashing", unit="img")\
\
        for future in iterable:\
            path, img_hash = future.result()\
            if img_hash:\
                all_hashes[path] = img_hash\
\
    # --- Step 2: Compare all hashes (O(n^2), but in-memory math is INSTANT) ---\
    print("\\n\uc0\u55358 \u56812  Comparing fingerprints to find burst groups...")\
    \
    visited_paths = set()\
    all_burst_groups = []\
    \
    # Sort paths for deterministic grouping\
    sorted_paths = sorted(all_hashes.keys(), key=lambda p: p.name)\
    \
    for path in sorted_paths:\
        if path in visited_paths:\
            continue\
            \
        current_group = [path]\
        visited_paths.add(path)\
        \
        # Compare this hash to all other *unvisited* hashes\
        for other_path in sorted_paths:\
            if other_path in visited_paths:\
                continue\
                \
            hash1 = all_hashes.get(path)\
            hash2 = all_hashes.get(other_path)\
            \
            if hash1 and hash2:\
                # This is the "magic": (hash1 - hash2) is the "visual distance"\
                distance = hash1 - hash2\
                if distance <= BURST_SIMILARITY_THRESHOLD:\
                    # They are similar! Add to group.\
                    current_group.append(other_path)\
                    visited_paths.add(other_path)\
        \
        # We only care about "groups" (more than 1 image)\
        if len(current_group) > 1:\
            all_burst_groups.append(current_group)\
\
    # --- Step 3: Move files into burst folders ---\
    if not all_burst_groups:\
        print("\\n\uc0\u9989  No burst groups found. All images are unique!")\
        return\
\
    print(f"\\n\uc0\u55357 \u56513  Found \{len(all_burst_groups)\} burst groups. Stacking them now...")\
    \
    for i, group in enumerate(all_burst_groups):\
        # Create the new folder name, e.g., "burst-001"\
        folder_name = f"burst-\{i+1:03d\}"\
        folder_path = directory / folder_name\
        \
        print(f"\\n\uc0\u55357 \u56514  \{folder_name\}/ (\{len(group)\} files)")\
        \
        if not dry_run:\
            folder_path.mkdir(exist_ok=True)\
            \
        for file_path in group:\
            new_file_path = folder_path / file_path.name\
            if not dry_run:\
                try:\
                    shutil.move(str(file_path), str(new_file_path))\
                    print(f"   \uc0\u8594  Moved \{file_path.name\}")\
                except Exception as e:\
                    print(f"   \uc0\u10060  FAILED to move \{file_path.name\}: \{e\}")\
            else:\
                print(f"   [PREVIEW] Would move \{file_path.name\} to \{folder_name\}/")\
\
    print("\\n\uc0\u10024  Burst stacking complete!")\
# --- END NEW FUNCTION ---\
\
\
def main():\
    """Main entry point"""\
    current_dir = Path.cwd()\
    \
    # --- V5.0: NEW FLAG LOGIC ---\
    # Check for our new v5 flags\
    dry_run = "--preview" in sys.argv or "-p" in sys.argv\
    group_bursts = "--group-bursts" in sys.argv or "-b" in sys.argv\
    \
    if group_bursts:\
        if not V5_LIBS_AVAILABLE:\
            print("\uc0\u10060  FATAL: '--group-bursts' requires the 'imagehash' library.")\
            print("   Please run: pip install imagehash")\
            return\
        # --- RUN THE BURST STACKER ---\
        if dry_run:\
             print("\\n\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
             print("   RUNNING BURST STACKER IN PREVIEW MODE - NO FILES WILL BE MOVED  ")\
             print("\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
        group_bursts_in_directory(current_dir, dry_run)\
        \
        if dry_run:\
            print("\\n\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
            print("          DRY RUN COMPLETE - NO FILES WERE MOVED             ")\
            print("\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
        else:\
            print("\\n\uc0\u10024  Done!\\n")\
        return # <-- We are done, exit the script.\
    \
    # --- IF NO V5 FLAGS, RUN THE NORMAL V4.1 INGEST ---\
    \
    if dry_run:\
        print("\\n\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
        print("   RUNNING INGEST IN PREVIEW MODE (DRY RUN) - NO FILES WILL BE MOVED  ")\
        print("\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
    \
    print("\\n\uc0\u55356 \u57256  BakLLaVA Photo Organizer --- (Ingest Mode)")\
    print(f"\uc0\u55357 \u56513  Current directory: \{current_dir\}")\
    \
    # Choose destination folder\
    print(f"\\n\uc0\u55356 \u57263  Default destination is: \{DEFAULT_DESTINATION_BASE\}")\
    new_dest_path = input("   Press ENTER to use default, or type a new path: ").strip()\
\
    chosen_destination: Path\
    if not new_dest_path:\
        chosen_destination = DEFAULT_DESTINATION_BASE\
        print(f"   Using default destination.")\
    else:\
        chosen_destination = Path(new_dest_path).expanduser()\
        print(f"   Using new destination: \{chosen_destination\}")\
    \
    # Ensure the chosen destination folder exists\
    try:\
        # --- V4.1 DRY RUN LOGIC ---\
        if not dry_run:\
            chosen_destination.mkdir(parents=True, exist_ok=True)\
        else:\
            print(f"   [PREVIEW] Would create destination folder: \{chosen_destination\}")\
            \
    except Exception as e:\
        print(f"\uc0\u10060  Error creating destination folder: \{e\}")\
        print("   Please check the path and permissions. Exiting.")\
        return\
    \
    # Choose model\
    print(f"\\n\uc0\u55358 \u56598  Default model is: \{DEFAULT_MODEL_NAME\}")\
    \
    # --- V4.1 "FAIL FAST" CHECK ---\
    available_models = get_available_models()\
    if available_models is None:\
        print("\\n\uc0\u10060  FATAL: Could not connect to Ollama server.")\
        print("   Please ensure Ollama is running.")\
        return # <-- STOPS THE SCRIPT.\
    \
    if available_models:\
        print(f"   Available models: \{', '.join(available_models)\}")\
    else:\
        print("   \uc0\u9888 \u65039   No models found. Run 'ollama pull bakllava' to install one.")\
    \
    new_model = input("   Press ENTER to use default, or type a model name: ").strip()\
    \
    chosen_model: str\
    if not new_model:\
        chosen_model = DEFAULT_MODEL_NAME\
        print(f"   Using default model.")\
    else:\
        # Validate the model exists\
        if available_models and new_model not in available_models:\
            print(f"\uc0\u9888 \u65039   Warning: '\{new_model\}' not found in available models.")\
            print(f"   Available: \{', '.join(available_models)\}")\
            confirm = input("   Continue anyway? (y/n): ").strip().lower()\
            if confirm != 'y':\
                print("Cancelled.")\
                return\
        chosen_model = new_model\
        print(f"   Using model: \{chosen_model\}")\
\
    # Confirm before processing\
    response = input("\\n\uc0\u9654 \u65039   Process all images in this directory? (y/n): ")\
    if response.lower() != 'y':\
        print("Cancelled.")\
        return\
    \
    # Pass all our new parameters\
    process_directory(current_dir, chosen_destination, chosen_model, dry_run)\
    \
    if dry_run:\
        print("\\n\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
        print("          DRY RUN COMPLETE - NO FILES WERE MOVED             ")\
        print("\uc0\u55356 \u57281  ======================================================= \u55356 \u57281 ")\
    else:\
        print("\\n\uc0\u10024  Done!\\n")\
\
\
if __name__ == "__main__":\
    main()\
\
}